# mlr-playground


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

This is a collection of implementations -documented with explanations-
of some key research papers on machine learning, deep learning and
related algorithms and models, inspired by [this
website](https://nn.labml.ai/index.html) from
[@labmlai](https://twitter.com/labmlai).

The main goal of this repository is to be a playground where I can
develop a hands-on understanding of these algorithms and models, and
where I can practice my skills of translating research papers into
working code.

My main “tools of the trade” are Python and PyTorch. My
coding/development platform comprises VS Code, Jupyter Lab, nbdev and
Paperspace Gradient. I use nbdev and Quarto for publishing.

## Papers

The list of papers and associated notebooks include the following, in a
somehow not very strict taxonomy:

<details open>
<summary>
Transformers
</summary>

1.  Attention-Free Transformer: [An Attention Free
    Transformer](https://arxiv.org/abs/2105.14103). \>
    [Notebook](transformers.mha.html)
2.  Relative Attention Transformer: [Transformer-XL: Attentive Language
    Models Beyond a Fixed-Length
    Context](https://arxiv.org/abs/1901.02860). \>
    [Notebook](transformers.relative_mha.html)

</details>

## Install

``` sh
pip install mlr_playground
```
